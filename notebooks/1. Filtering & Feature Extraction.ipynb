{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "LIGHTCURVES_PATH = DATA_PATH + 'lightcurves/'\n",
    "FEATURES_PATH = DATA_PATH + 'features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import measurements, extract\n",
    "import matplotlib.pyplot as plt\n",
    "import inputs2\n",
    "from multiprocessing import cpu_count, Pool, current_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_ids_list(df_lcs):\n",
    "    return df_lcs.index.get_level_values('ID').unique().format()\n",
    "\n",
    "def print_num_ids_shape(df_lcs):\n",
    "    unique_ids = unique_ids_list(df_lcs)\n",
    "    print('Num IDs: {}  Shape: {}'.format(len(unique_ids), df_lcs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import __transient__ catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = inputs2.load_transient_catalog()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import __transient__ lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 4869  Shape: (440469, 3)\n"
     ]
    }
   ],
   "source": [
    "filename = 'transient_lightcurves_clean.csv'\n",
    "indir = LIGHTCURVES_PATH; filepath = indir + filename\n",
    "df_transient_noclass = pd.read_csv(filepath)\n",
    "df_transient_noclass = df_transient_noclass.set_index(['ID', 'observation_id'])\n",
    "df_transient_noclass.head()\n",
    "print_num_ids_shape(df_transient_noclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import __non-transient__ light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids unicos \n",
    "ids = df_transient_noclass.index.get_level_values('ID').unique()\n",
    "\n",
    "# escoger aleatoriamente 25% de los indices\n",
    "\n",
    "testInd = np.random.choice(ids, int(0.25*len(ids)),replace=False)\n",
    "\n",
    "#sacar dataframes\n",
    "\n",
    "testdf = df_transient_noclass[df_transient_noclass.index.get_level_values('ID').isin(testInd)]\n",
    "trainningfd =  df_transient_noclass[~df_transient_noclass.index.get_level_values('ID').isin(testInd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 16940  Shape: (1802695, 3)\n"
     ]
    }
   ],
   "source": [
    "filename = 'nontransient_lightcurves_clean.csv'\n",
    "indir = LIGHTCURVES_PATH; filepath = indir + filename\n",
    "df_nont = pd.read_csv(filepath)\n",
    "\n",
    "df_nont = df_nont.set_index(['ID', 'observation_id'])\n",
    "print_num_ids_shape(df_nont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tra = df_transient_noclass.join(df_cat, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mag</th>\n",
       "      <th>Magerr</th>\n",
       "      <th>MJD</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TranID1409030010044114444</th>\n",
       "      <th>0</th>\n",
       "      <td>18.8765</td>\n",
       "      <td>0.166417</td>\n",
       "      <td>53766.089871</td>\n",
       "      <td>SN?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0519</td>\n",
       "      <td>0.281733</td>\n",
       "      <td>53990.458866</td>\n",
       "      <td>SN?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.2199</td>\n",
       "      <td>0.295764</td>\n",
       "      <td>53996.286004</td>\n",
       "      <td>SN?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.1192</td>\n",
       "      <td>0.495390</td>\n",
       "      <td>54385.205789</td>\n",
       "      <td>SN?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.3289</td>\n",
       "      <td>0.195002</td>\n",
       "      <td>54355.282285</td>\n",
       "      <td>SN?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mag    Magerr           MJD  \\\n",
       "ID                        observation_id                                    \n",
       "TranID1409030010044114444 0               18.8765  0.166417  53766.089871   \n",
       "                          1               20.0519  0.281733  53990.458866   \n",
       "                          2               20.2199  0.295764  53996.286004   \n",
       "                          3               21.1192  0.495390  54385.205789   \n",
       "                          4               19.3289  0.195002  54355.282285   \n",
       "\n",
       "                                         class  \n",
       "ID                        observation_id        \n",
       "TranID1409030010044114444 0                SN?  \n",
       "                          1                SN?  \n",
       "                          2                SN?  \n",
       "                          3                SN?  \n",
       "                          4                SN?  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tra.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Non-Transient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nont['class'] = 'non-transient'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_light_curves(df_lcs, min_obs):\n",
    "    df_count = df_lcs.groupby('ID', as_index=True).count()\n",
    "    df_count['ObsCount'] = df_count['Mag']\n",
    "    df_count = df_count[['ObsCount']]\n",
    "    df_lcs_with_counts = df_lcs.join(df_count, how='inner')\n",
    "    # Remove objects with less than min_obs\n",
    "    df_filtered = df_lcs_with_counts[df_lcs_with_counts.ObsCount >= min_obs]\n",
    "#     # Remove ObsCount\n",
    "#     df_filtered = df_filtered.drop(['ObsCount'], axis=1)\n",
    "    return df_filtered\n",
    "\n",
    "def sample(df_lcs, num_samples):\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "    # Sample non-transient subset of same size as transients\n",
    "    IDs = np.random.choice(unique_ids_list(df_lcs), size=num_samples, replace=False)\n",
    "#     print(IDs); return\n",
    "    df_sampled = df_nont.loc[IDs]\n",
    "    return df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter __transient__ light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 4269  Shape: (438897, 5)\n"
     ]
    }
   ],
   "source": [
    "df_tra_5 = filter_light_curves(df_tra, 5)\n",
    "print_num_ids_shape(df_tra_5)\n",
    "\n",
    "del df_tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter __non-transient__ lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 15193  Shape: (1798465, 5)\n"
     ]
    }
   ],
   "source": [
    "df_nont_5 = filter_light_curves(df_nont, 5)\n",
    "print_num_ids_shape(df_nont_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df_lcs, copies=0):\n",
    "    df_oversample = df_lcs.copy()\n",
    "    df_oversample['copy_num'] = 0\n",
    "    for i in range(1, copies+1):\n",
    "        df_temp = df_lcs.copy()\n",
    "        df_temp['copy_num'] = i\n",
    "        df_temp['Mag'] = np.random.normal(df_lcs.Mag, df_lcs.Magerr)\n",
    "        df_oversample = df_oversample.append(df_temp)\n",
    "        \n",
    "    df_oversample = df_oversample.set_index(['copy_num'], append=True)\n",
    "    return df_oversample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversample __transient__ light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 4269  Shape: (4827867, 5)\n"
     ]
    }
   ],
   "source": [
    "df_tra_5_os = oversample(df_tra_5, 10)\n",
    "print_num_ids_shape(df_tra_5_os)\n",
    "\n",
    "del df_tra_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Oversample\" __nontransient__ light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num IDs: 15193  Shape: (1798465, 5)\n"
     ]
    }
   ],
   "source": [
    "df_nont_5_os = oversample(df_nont_5, 0)\n",
    "print_num_ids_shape(df_nont_5)\n",
    "\n",
    "del df_nont_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df_lcs):\n",
    "    pid = (current_process().name.split('-')[1])\n",
    "    print(\"Process \", pid ,\" starting...\")\n",
    "    \n",
    "    print(\"Process \", pid ,\" extracting num_copy...\")\n",
    "    # Extract num_copy list\n",
    "    num_copy_list = df_lcs.index.get_level_values('copy_num').unique()    \n",
    "    num_copies = len(num_copy_list)\n",
    "    \n",
    "    \n",
    "    print(\"Process \", pid ,\" extracting id_list...\")\n",
    "    # Extract IDs list\n",
    "    unique_ids_list = df_lcs.index.get_level_values('ID').unique()\n",
    "    num_ids = len(unique_ids_list)\n",
    "\n",
    "    \n",
    "    print(\"Process \", pid ,\" creating ouput vars...\")\n",
    "    # Create empty feature dict\n",
    "    feats_dict = extract.feature_dict(30)\n",
    "    feats_dict['ObsCount'] = []\n",
    "    feats_dict['Class'] = []\n",
    "    \n",
    "    \n",
    "    # Add 'ID' and 'copy_num' index lists\n",
    "    index_id_list = []\n",
    "    index_copy_num_list = []\n",
    "    \n",
    "    \n",
    "    print(\"Process \", pid ,\" starting processing loop...\")\n",
    "    num_objects = num_ids*num_copies\n",
    "    for num_copy in num_copy_list:\n",
    "        for i, obj_id in enumerate(unique_ids_list):\n",
    "            # Print status\n",
    "            current_object_i = (num_copy+1)*i\n",
    "#             if(current_object_i%int(num_objects/1000) == 0):\n",
    "            print('Process #:',pid , \" \", current_object_i, '/', num_objects)\n",
    "            # Get current object light curve\n",
    "            df_object = df_lcs.loc[obj_id,:,num_copy]\n",
    "#             print(feats_dict)\n",
    "#             break\n",
    "            # Get features\n",
    "            obj_feats = extract.features(df_object, feats_dict)\n",
    "            \n",
    "#             print(obj_feats)\n",
    "#             break\n",
    "            # Append features\n",
    "            for k,v in obj_feats.items():\n",
    "                feats_dict[k].append(obj_feats[k])\n",
    "            # Append Indexes\n",
    "            index_id_list.append(obj_id)\n",
    "            index_copy_num_list.append(num_copy)\n",
    "            # Append class and obs_count\n",
    "            assert(len(df_object['class'].unique()) == 1)\n",
    "            assert(len(df_object['ObsCount'].unique()) == 1)\n",
    "            assert(df_object['ObsCount'].unique()[0] == df_object.shape[0])\n",
    "            feats_dict['Class'].append(df_object['class'].unique()[0])\n",
    "            feats_dict['ObsCount'].append(df_object.shape[0])\n",
    "            \n",
    "    # Create feature dataframe\n",
    "    df_feats = pd.DataFrame(feats_dict).set_index([index_id_list,index_copy_num_list])\n",
    "    df_feats.index.names = ['ID', 'copy_num']\n",
    "    \n",
    "    # NEED TO SAVE A COPY OF DF JUST IN CASE\n",
    "    outdir = FEATURES_PATH\n",
    "    df_feats.to_csv(outdir + str(pid) + \".csv\")\n",
    "    return df_feats\n",
    "\n",
    "def save_features(df_feats, obj_type):\n",
    "    outdir = FEATURES_PATH\n",
    "    filename_raw = '{}.csv'\n",
    "    filename = filename_raw.format(obj_type)\n",
    "#     assert(df_feats.shape[1]==32) # 30 + ['num_obs'+'class']\n",
    "    df_feats.to_csv(outdir + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df_all, transient, min_obs):\n",
    "    obj_type = 'T' if transient else 'NT'\n",
    "    \n",
    "    #init parallel params\n",
    "    cores = cpu_count() \n",
    "    pool = Pool(cores)\n",
    "    \n",
    "    #split dataframe into equal parts\n",
    "    #one for each core\n",
    "    ids = np.array(df_all.index.get_level_values('ID').unique())\n",
    "    np.random.shuffle(ids)\n",
    "    \n",
    "    split_ids = np.array_split(ids, cores)\n",
    "    \n",
    "    dfs = [df_all[df_all.index.get_level_values('ID').isin(id_set)] for id_set in split_ids]\n",
    "    \n",
    "    \n",
    "    #execute extraction in parallel\n",
    "    \n",
    "    feats = pd.concat(pool.map(extract_features, dfs))\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "#     return '--------------'\n",
    "    # Generate features based on light curves in parallel\n",
    "    df_feats = extract_features(df_all,obj_type)\n",
    "    spl = np.array_split(data, partitions)\n",
    "\n",
    "    \n",
    "    save_features(df_feats, obj_type)\n",
    "    \n",
    "    # Log Finished\n",
    "    print('Finished task type={} obs={}'.format(obj_type, min_obs) )\n",
    "    return df_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features __transient__ light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  71  starting...\n",
      "Process  71  starting processing loop...\n",
      "Process  71  extracting num_copy...\n",
      "Process  71  extracting id_list...\n",
      "Process  71  creating ouput vars...\n",
      "Process #: 71   0 / 11748\n",
      "Process  72  starting...\n",
      "Process  72  extracting id_list...\n",
      "Process  72  extracting num_copy...\n",
      "Process  72  creating ouput vars...\n",
      "Process  72  starting processing loop...\n",
      "Process #: 72   0 / 11737\n",
      "Process  73  starting...\n",
      "Process  73  extracting num_copy...\n",
      "Process  73  extracting id_list...\n",
      "Process  73  creating ouput vars...\n",
      "Process  73  starting processing loop...\n",
      "Process #: 73   0 / 11737\n",
      "Process  74  starting...\n",
      "Process  74  extracting num_copy...\n",
      "Process  74  extracting id_list...\n",
      "Process  74  creating ouput vars...\n",
      "Process  74  starting processing loop...\n",
      "Process #: 74   0 / 11737\n",
      "Process #: 72   1 / 11737\n",
      "Process #: 72   2 / 11737\n",
      "Process #: 74   1 / 11737\n",
      "Process #: 74   2 / 11737\n",
      "Process #: 74   3 / 11737\n",
      "Process #: 72   3 / 11737\n",
      "Process #: 72   4 / 11737\n",
      "Process #: 73   1 / 11737\n",
      "Process #: 72   5 / 11737\n",
      "Process #: 73   2 / 11737\n",
      "Process #: 73   3 / 11737\n",
      "Process #: 72   6 / 11737\n",
      "Process #: 73   4 / 11737\n",
      "Process #: 72   7 / 11737\n",
      "Process #: 73   5 / 11737\n",
      "Process #: 72   8 / 11737\n",
      "Process #: 72   9 / 11737\n",
      "Process #: 72   10 / 11737\n",
      "Process #: 71   1 / 11748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0de6e062d015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_tra_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tra_5_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-50b719e91bf2>\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(df_all, transient, min_obs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#execute extraction in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 74   4 / 11737\n",
      "Process #: 72   11 / 11737\n",
      "Process #: 71   2 / 11748\n",
      "Process #: 72   12 / 11737\n",
      "Process #: 74   5 / 11737\n",
      "Process #: 72   13 / 11737\n",
      "Process #: 72   14 / 11737\n",
      "Process #: 73   6 / 11737\n",
      "Process #: 74   6 / 11737\n",
      "Process #: 73   7 / 11737\n",
      "Process #: 74   7 / 11737\n",
      "Process #: 73   8 / 11737\n",
      "Process #: 71   3 / 11748\n",
      "Process #: 73   9 / 11737\n",
      "Process #: 71   4 / 11748\n",
      "Process #: 71   5 / 11748\n",
      "Process #: 74   8 / 11737\n",
      "Process #: 71   6 / 11748\n",
      "Process #: 71   7 / 11748\n",
      "Process #: 74   9 / 11737\n",
      "Process #: 73   10 / 11737\n",
      "Process #: 74   10 / 11737\n",
      "Process #: 74   11 / 11737\n",
      "Process #: 74   12 / 11737\n",
      "Process #: 72   15 / 11737\n",
      "Process #: 73   11 / 11737\n",
      "Process #: 72   16 / 11737\n",
      "Process #: 72   17 / 11737\n",
      "Process #: 71   8 / 11748\n",
      "Process #: 72   18 / 11737\n",
      "Process #: 74   13 / 11737\n",
      "Process #: 72   19 / 11737\n",
      "Process #: 71   9 / 11748\n",
      "Process #: 74   14 / 11737\n",
      "Process #: 74   15 / 11737\n",
      "Process #: 74   16 / 11737\n",
      "Process #: 71   10 / 11748\n",
      "Process #: 73   12 / 11737\n",
      "Process #: 74   17 / 11737\n",
      "Process #: 74   18 / 11737\n",
      "Process #: 74   19 / 11737\n",
      "Process #: 74   20 / 11737\n",
      "Process #: 71   11 / 11748\n",
      "Process #: 71   12 / 11748\n",
      "Process #: 74   21 / 11737\n",
      "Process #: 74   22 / 11737\n",
      "Process #: 71   13 / 11748\n",
      "Process #: 73   13 / 11737\n",
      "Process #: 72   20 / 11737\n",
      "Process #: 73   14 / 11737\n",
      "Process #: 73   15 / 11737\n",
      "Process #: 72   21 / 11737\n",
      "Process #: 74   23 / 11737\n",
      "Process #: 74   24 / 11737\n",
      "Process #: 73   16 / 11737\n",
      "Process #: 73   17 / 11737\n",
      "Process #: 73   18 / 11737\n",
      "Process #: 73   19 / 11737\n",
      "Process #: 71   14 / 11748\n",
      "Process #: 73   20 / 11737\n",
      "Process #: 71   15 / 11748\n",
      "Process #: 74   25 / 11737\n",
      "Process #: 72   22 / 11737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauro/anaconda3/lib/python3.6/site-packages/sncosmo/models.py:697: RuntimeWarning: overflow encountered in power\n",
      "  10. ** (-0.4 * self._colorlaw(wave) * self._parameters[2]))\n",
      "/home/mauro/anaconda3/lib/python3.6/site-packages/sncosmo/models.py:697: RuntimeWarning: invalid value encountered in multiply\n",
      "  10. ** (-0.4 * self._colorlaw(wave) * self._parameters[2]))\n",
      "/home/mauro/anaconda3/lib/python3.6/site-packages/sncosmo/models.py:697: RuntimeWarning: overflow encountered in power\n",
      "  10. ** (-0.4 * self._colorlaw(wave) * self._parameters[2]))\n",
      "/home/mauro/anaconda3/lib/python3.6/site-packages/sncosmo/models.py:697: RuntimeWarning: invalid value encountered in multiply\n",
      "  10. ** (-0.4 * self._colorlaw(wave) * self._parameters[2]))\n",
      "/home/mauro/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 72   23 / 11737\n",
      "Process #: 71   16 / 11748\n",
      "Process #: 74   26 / 11737\n",
      "Process #: 71   17 / 11748\n",
      "Process #: 74   27 / 11737\n",
      "Process #: 71   18 / 11748\n",
      "Process #: 72   24 / 11737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauro/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 71   19 / 11748\n",
      "Process #: 72   25 / 11737\n",
      "Process #: 74   28 / 11737\n",
      "Process #: 74   29 / 11737\n",
      "Process #: 72   26 / 11737\n",
      "Process #: 73   21 / 11737\n",
      "Process #: 71   20 / 11748\n",
      "Process #: 74   30 / 11737\n",
      "Process #: 72   27 / 11737\n",
      "Process #: 72   28 / 11737\n",
      "Process #: 71   21 / 11748\n",
      "Process #: 71   22 / 11748\n",
      "Process #: 71   23 / 11748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-71:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 74   31 / 11737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-85-35ac89203c75>\", line 42, in extract_features\n",
      "    obj_feats = extract.features(df_object, feats_dict)\n",
      "  File \"/home/mauro/Documents/U/monitoriaInv/CRTS-transient-recognition-revised/notebooks/extract.py\", line 16, in features\n",
      "    df.Mag, df.Magerr, df.MJD)\n",
      "  File \"/home/mauro/Documents/U/monitoriaInv/CRTS-transient-recognition-revised/notebooks/measurements.py\", line 228, in poly_params\n",
      "    p4 = np.polyfit(x, y, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 73   22 / 11737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-74:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 72   29 / 11737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/mauro/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-85-35ac89203c75>\", line 42, in extract_features\n",
      "    obj_feats = extract.features(df_object, feats_dict)\n",
      "  File \"/home/mauro/Documents/U/monitoriaInv/CRTS-transient-recognition-revised/notebooks/extract.py\", line 16, in features\n",
      "    df.Mag, df.Magerr, df.MJD)\n",
      "  File \"/home/mauro/Documents/U/monitoriaInv/CRTS-transient-recognition-revised/notebooks/measurements.py\", line 225, in poly_params\n",
      "    p1 = np.polyfit(x, y, 1)\n",
      "Process ForkPoolWorker-73:\n",
      "KeyboardInterrupt\n",
      "   <_ast.Module object at 0x7ff9914086a0>\n",
      "                        ^^^\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #: 72   30 / 11737\n",
      "Process #: 72   31 / 11737\n",
      "Process #: 72   32 / 11737\n",
      "Process #: 72   33 / 11737\n",
      "Process #: 72   34 / 11737\n"
     ]
    }
   ],
   "source": [
    "df_tra_feats = generate_features(df_tra_5_os, transient=True, min_obs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "STARTING NON TRANSIENTS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\"[0]*100)\n",
    "print(\"STARTING NON TRANSIENTS \\n\"*100)   \n",
    "for i in range(10):\n",
    "    print(\"-\"[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nont_feats = generate_features(df_nont_5_os, transient=False, min_obs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
